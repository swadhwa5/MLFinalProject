{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "DataAugmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.12 64-bit ('pytorch_p37': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "14f67cdccdf06abada5969147d66d8a0303fc958affdfcadd6d47bed05461cdf"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "from tempfile import TemporaryFile\n",
        "from PIL import Image, ImageEnhance\n",
        "from os import listdir\n",
        "import imghdr\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "from skimage import filters\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import scipy\n",
        "import random"
      ],
      "outputs": [],
      "metadata": {
        "id": "1gooWBOWPxQb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rmdir './Data_full/.ipynb_checkpoints'"
      ],
      "outputs": [],
      "metadata": {
        "id": "Zhp53FBiP15A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "#Load Data\n",
        "# return array of images\n",
        "def loadImages(path):\n",
        "    imagesList = listdir(path)\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for image in imagesList:\n",
        "      if imghdr.what(path + image) == 'png':\n",
        "        if (image[len(image) - 13] == '1' and image[6].isalpha()): # only add 5 of each image, only add alphabetical values\n",
        "          img = Image.open(path + image)\n",
        "          imgs.append(img)\n",
        "          labels.append(image[6]) # assumes that filename structure is 'handx_[label]_....'\n",
        "    return imgs, labels\n",
        "\n",
        "# Convert png img array to array np arrays\n",
        "def ImagesToArray(imgs):\n",
        "  imgs_array = []\n",
        "  for img in imgs:\n",
        "    img_array = np.array(img)\n",
        "    imgs_array.append(img_array)\n",
        "  return imgs_array\n",
        "\n",
        "# Reshape Images   \n",
        "def shape600(x):\n",
        "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
        "  for i, img in enumerate(x):\n",
        "    x_pad_width = (600 - img.shape[0])//2\n",
        "    y_pad_width = (600 - img.shape[1])//2\n",
        "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
        "  return reshaped_array\n",
        "\n",
        "# Normalize images\n",
        "def Normalize(imgs):\n",
        "  new_imgs = []\n",
        "  for img in imgs:\n",
        "      # flat_img = img.flatten()\n",
        "      m = np.mean(img)\n",
        "      std = np.std(img)\n",
        "      img = (img-m)/std\n",
        "      new_imgs.append(img)\n",
        "  return new_imgs\n",
        "\n",
        "# x is input image, sd is how much to blur\n",
        "def blur(imgs, sd=1):\n",
        "  filtered_img = np.zeros((imgs.shape[0], 600, 600, 3))\n",
        "  for i in range(imgs.shape[0]):\n",
        "    filtered_img[i,:,:,:] = skimage.filters.gaussian(imgs[i,:,:,:], sigma=sd)\n",
        "    #filtered_img.save('./Filter_gaussian/img_' + i + '_gaussianfilt.png')\n",
        "  return filtered_img\n",
        "\n",
        "def Scale(imgs):\n",
        "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
        "  for i, img in enumerate(imgs):\n",
        "    ratio = random.uniform(.3, .7)\n",
        "    x = int(ratio * 600 / 2)\n",
        "    scaled = img[x:600-x, x:600-x]\n",
        "    # scaled = cv2.imread(scaled)\n",
        "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
        "    scaled_images[i] = res\n",
        "  return scaled_images\n",
        "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
        "\n",
        "def Brighten_light(imgs):\n",
        "  Brightened_light_images = np.zeros((len(imgs), 600, 600, 3))\n",
        "  for i in range (imgs.shape[0]):\n",
        "    Brightened_light_images[i] = imgs[i] + (0.2, 0.2, 0.2)\n",
        "    # light_img.save('./Brightness_light/img_' + str(i) + '_light.png')\n",
        "  return Brightened_light_images\n",
        "\n",
        "def Brighten_dark(imgs):\n",
        "  Brightened_dark_images = np.zeros((len(imgs), 600, 600, 3))\n",
        "  for i in range (imgs.shape[0]):\n",
        "    Brightened_dark_images[i] = imgs[i] - (0.2, 0.2, 0.2)\n",
        "    # dark_img.save('./Brightness_dark/img_' + str(i) + '_dark.png')\n",
        "  return Brightened_dark_images\n",
        "\n",
        "def Rotate30(imgs): \n",
        "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    rand_dir = random.choice([-1, 1])\n",
        "    new_img = rotate(img, rand_dir * 30) \n",
        "    rot30_imgs[i, :] = new_img\n",
        "  return rot30_imgs\n",
        "\n",
        "def VerticalFlip(imgs): \n",
        "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    new_img = np.fliplr(img)\n",
        "    flip_imgs[i, :, :, :] = new_img\n",
        "  return flip_imgs\n",
        "\n",
        "def Translation(imgs): \n",
        "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    rand_x = random.randrange(-150, 150, 50)\n",
        "    rand_y = random.randrange(-150, 150, 50)\n",
        "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
        "    new_img = warp(img,transform, mode=\"constant\")  \n",
        "    trans_imgs[i, :] = new_img\n",
        "  return trans_imgs\n",
        "\n",
        "# load png_images\n",
        "path = \"./Data_full/\"\n",
        "\n",
        "# images in an array named imgs\n",
        "imgs, labels = loadImages(path)\n",
        "\n",
        "print(len(imgs))\n",
        "\n",
        "# Step 1 convert png_images to np arrays\n",
        "imgs_array_before = ImagesToArray(imgs)\n",
        "\n",
        "def Augment(imgs_array_before, i):\n",
        "  # Step 2 Normalize images\n",
        "  imgs_array_normalize = Normalize(imgs_array_before)\n",
        "\n",
        "  # Step 3 Reshape the images\n",
        "  imgs_array_reshaped = shape600(imgs_array_normalize)\n",
        "\n",
        "  # Step 4 Blur the images\n",
        "  blurred_imgs = blur(imgs_array_reshaped, 10)\n",
        "\n",
        "  # Step 5 Scale the images\n",
        "  scaled_imgs = Scale(imgs_array_reshaped)\n",
        "\n",
        "  # Step 6 Brighten the images\n",
        "  light_imgs = Brighten_light(imgs_array_reshaped)\n",
        "  dark_imgs = Brighten_dark(imgs_array_reshaped)\n",
        "\n",
        "  # Step 7 Flip the images\n",
        "  flipped_imgs = VerticalFlip(imgs_array_reshaped)\n",
        "\n",
        "  # Step 8 Add translation to images\n",
        "  translated_imgs = Translation(imgs_array_reshaped)\n",
        "\n",
        "  # Step 9 Rotate 30 Degrees\n",
        "  rotated30_imgs = Rotate30(imgs_array_reshaped)\n",
        "  rotatedNeg30_imgs = RotateNeg30(imgs_array_reshaped)\n",
        "\n",
        "  # Step 10 combine all augmented images to np array of shape((num_augmentations + 1) * num_images, 600, 600, 3)\n",
        "  final_imgs_temp = np.concatenate((imgs_array_reshaped, blurred_imgs, light_imgs, dark_imgs, scaled_imgs, translated_imgs, flipped_imgs, rotated30_imgs, rotatedNeg30_imgs), 0)\n",
        "  print(final_imgs_temp.shape)\n",
        "  np.save('./FinalImages/imgs' + str(i) + '.npy', final_imgs_temp)\n",
        "  # Show the progression of images for each step\n",
        "  # fig, ax = plt.subplots(1, 11, figsize=(15,10))\n",
        "  # ax[0].imshow(imgs_array_before[0]) # Step 1\n",
        "  # ax[1].imshow(imgs_array_normalize[0]) # Step 2\n",
        "  # ax[2].imshow(imgs_array_reshaped[0]) # Step 3\n",
        "  # ax[3].imshow(blurred_imgs[0]) # Step 4\n",
        "  # ax[4].imshow(scaled_imgs[0]) # Step 5\n",
        "  # ax[5].imshow(light_imgs[0]) # Step 6\n",
        "  # ax[6].imshow(dark_imgs[0]) # Step 6\n",
        "  # ax[7].imshow(flipped_imgs[0]) # Step 7\n",
        "  # ax[8].imshow(translated_imgs[0]) # Step 8\n",
        "  # ax[9].imshow(rotated30_imgs[0]) # Step 9\n",
        "  # ax[10].imshow(rotatedNeg30_imgs[0]) # Step 9\n",
        "  return final_imgs_temp\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        }
      ],
      "metadata": {
        "id": "VaHsuJ2XP2_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "final_imgs = np.empty([0, 600, 600, 3])\n",
        "n = int(900/50)\n",
        "for i in range(n):\n",
        "  final_imgs_temp = Augment(imgs_array_before[i * 50:(i + 1) * 50], i)\n",
        "  final_imgs = np.concatenate((final_imgs, final_imgs_temp), 0)\n",
        "\n",
        "print(final_imgs.shape)\n",
        "np.save('./FinalImages/imgs.npy', final_imgs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/shreyawadhwa/miniconda3/envs/pytorch_p37/lib/python3.8/site-packages/skimage/_shared/utils.py:348: RuntimeWarning: Images with dimensions (M, N, 3) are interpreted as 2D+RGB by default. Use `multichannel=False` to interpret as 3D image with last dimension of length 3.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n",
            "(450, 600, 600, 3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "486000000 requested and 41156608 written",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/nv/9940m1bn7ds7j01x5g5qy0wc0000gn/T/ipykernel_37016/3946985219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfinal_imgs_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_array_before\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mfinal_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_imgs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/nv/9940m1bn7ds7j01x5g5qy0wc0000gn/T/ipykernel_37016/1324377342.py\u001b[0m in \u001b[0;36mAugment\u001b[0;34m(imgs_array_before, i)\u001b[0m\n\u001b[1;32m    144\u001b[0m   \u001b[0mfinal_imgs_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_array_reshaped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblurred_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdark_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflipped_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotated30_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotatedNeg30_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_imgs_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./FinalImages/imgs'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_imgs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;31m# Show the progression of images for each step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;31m# fig, ax = plt.subplots(1, 11, figsize=(15,10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/pytorch_p37/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    530\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniconda3/envs/pytorch_p37/lib/python3.8/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             for chunk in numpy.nditer(\n",
            "\u001b[0;31mOSError\u001b[0m: 486000000 requested and 41156608 written"
          ]
        }
      ],
      "metadata": {
        "id": "7rc9mVMmP4mx"
      }
    }
  ]
}