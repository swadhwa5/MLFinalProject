{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_FinalProject_Submission.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzfz70AgT9kvDsO9vL7WrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swadhwa5/MLFinalProject/blob/main/ML_FinalProject_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Final Project\n",
        "By: Shreya Wadhwa, Alan Zhang, Aidan Aug, Trisha Karani\n",
        "JHED: swadhwa, azhang, tkarani1, aaug1\n",
        "\n",
        "*Due: April 28th, 2022*"
      ],
      "metadata": {
        "id": "PAG0pquLrTt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:**\n",
        "\n",
        "This is the iPython/Jupyter Notebook for our Machine Learning Final Project. For this project, we decided to develop a Majority Vote classifer model over three different CNNs to train a model to recognize sign language letters. The project into the following sections:\n",
        "\n",
        "1. Required Packages for Running the Notebook\n",
        "\n",
        "2. Data Augmentation\n",
        "\n",
        "3. Model Implementation\n",
        "\n",
        "4. Model Training and Testing\n",
        "\n",
        "5. Conclusions and Future Works"
      ],
      "metadata": {
        "id": "uJwT7uddrzCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 Python Packages:\n",
        "\n",
        "This section is simply a compilation of all the required packages for every section in the notebook. Please make sure to run this prior to any of the other code sections."
      ],
      "metadata": {
        "id": "LmaqcEJXspEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIKJRQF6n6J0"
      },
      "outputs": [],
      "source": [
        "## Data Processing, Augmentation, and Feature Engineering:\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from os import listdir\n",
        "import imghdr\n",
        "import skimage\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "\n",
        "## Model Implementation\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import skimage\n",
        "from skimage.transform import rotate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Data Augmentation and Feature Engineering\n",
        "\n",
        "For Data Augmentation, we decided to increase our dataset via the following processes:\n",
        "1. Blur\n",
        "2. Brighten\n",
        "3. Rotate\n",
        "4. Translate\n",
        "5. Zoom"
      ],
      "metadata": {
        "id": "MVEhis2gTfRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadImages(path):\n",
        "    imagesList = listdir(path)\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for image in imagesList:\n",
        "      if imghdr.what(path + image) == 'png':\n",
        "        if (image[6].isalpha()): # only add 5 of each image, only add alphabetical values\n",
        "          img = Image.open(path + image)\n",
        "          imgs.append(img)\n",
        "          labels.append(ord(image[6]) - ord('a')) # assumes that filename structure is 'handx_[label]_....'\n",
        "    return imgs, labels\n",
        "\n",
        "# Convert png img array to array np arrays\n",
        "# Input: PNG image array\n",
        "# Output: a list of numpy images\n",
        "# Works?: Yes\n",
        "def ImagesToArray(imgs):\n",
        "  imgs_array = []\n",
        "  for img in imgs:\n",
        "    img_array = np.array(img)\n",
        "    imgs_array.append(img_array)\n",
        "  return imgs_array\n",
        "\n",
        "# Zero pad all images\n",
        "# Input: list of numpy images\n",
        "# Output: numpy array of N 600x600 images with 3 channels\n",
        "# Works?: Yes, but might not be necessary\n",
        "def shape600(x):\n",
        "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
        "  for i, img in enumerate(x):\n",
        "    x_pad_width = (600 - img.shape[0])//2\n",
        "    y_pad_width = (600 - img.shape[1])//2\n",
        "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
        "  return reshaped_array\n",
        "\n",
        "# Normalizes images... based on... what?\n",
        "# Input: image array\n",
        "# Output: a list of numpy arrays\n",
        "# Works?: ??? Not entirely sure if this is the correct method though, based on online implementations of AlexNet\n",
        "def Normalize(imgs):\n",
        "  new_imgs = []\n",
        "  for img in imgs:\n",
        "      # flat_img = img.flatten()\n",
        "      m = np.mean(img)\n",
        "      std = np.std(img)\n",
        "      img = (img-m)/std\n",
        "      new_imgs.append(img)\n",
        "  return new_imgs\n",
        "\n",
        "################### DATA AUGMENTATION ######################\n",
        "# x is input image, sd is how much to blur\n",
        "def blur(imgs, sd=1):\n",
        "  filtered_img = np.zeros((imgs.shape[0], 600, 600, 3))\n",
        "  for i in range(imgs.shape[0]):\n",
        "    filtered_img[i,:,:,:] = skimage.filters.gaussian(imgs[i,:,:,:], sigma=sd)\n",
        "    #filtered_img.save('./Filter_gaussian/img_' + i + '_gaussianfilt.png')\n",
        "  return filtered_img\n",
        "\n",
        "def Scale(imgs):\n",
        "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
        "  for i, img in enumerate(imgs):\n",
        "    # ratio = random.randrange(.2, .5, .1)\n",
        "    ratio = random.choice([0.1, 0.2, 0.3, 0.4])\n",
        "    x = int(ratio * 600 / 2)\n",
        "    scaled = img[x:600-x, x:600-x]\n",
        "    # scaled = cv2.imread(scaled)\n",
        "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
        "    scaled_images[i] = res\n",
        "  return scaled_images\n",
        "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
        "\n",
        "def Rotate30(imgs): \n",
        "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    rand_dir = random.choice([-1, 1])\n",
        "    new_img = rotate(img, rand_dir * 30) \n",
        "    rot30_imgs[i, :] = new_img\n",
        "  return rot30_imgs\n",
        "\n",
        "def VerticalFlip(imgs): \n",
        "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    new_img = np.fliplr(img)\n",
        "    flip_imgs[i, :, :, :] = new_img\n",
        "  return flip_imgs\n",
        "\n",
        "def Translation(imgs): \n",
        "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    rand_x = random.randrange(-150, 150, 50)\n",
        "    rand_y = random.randrange(-150, 150, 50)\n",
        "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
        "    new_img = warp(img,transform, mode=\"constant\")  \n",
        "    trans_imgs[i, :] = new_img\n",
        "  return trans_imgs"
      ],
      "metadata": {
        "id": "fc-uo79W01LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Model Implementation\n",
        "\n",
        "For our model, we decided to implement a majority vote classifier based on three Convolutional Neural Networks, each with differing structures. Each model structure has basis in other current models."
      ],
      "metadata": {
        "id": "u_uiqA9Jr35T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: LeNet with 3 Channels\n",
        "\n",
        "LeNet was one of the first convolutional neural network (CNN) models used on 28x28 black and white images. While it is simple, it was one of the first uses of the backpropgation algorithm in practical applications: specifically, reading handwritten numbers. In 1990, there was an error rate of 1% and rejection rate of about 9%. The model structure is as follows:\n",
        "1. 2 convolutional layers\n",
        "2. 2 pooling layers\n",
        "3. 3 fully-connected\n",
        "\n",
        "In this implementation, we make slight modifications to this network and apply it to RGB images.\n",
        "\n",
        "LeCun, Y.; Boser, B.; Denker, J. S.; Henderson, D.; Howard, R. E.; Hubbard, W. & Jackel, L. D. (1989). Backpropagation applied to handwritten zip code recognition. Neural Computation, 1(4):541-551.[1]"
      ],
      "metadata": {
        "id": "mnGXysz-HVo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import skimage\n",
        "from skimage.transform import rotate\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "J7IIrTDx25FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(16 * 5 * 5, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(84, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1HUiuN6C2kJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: AlexNet\n",
        "\n",
        "AlexNet was one of the breakthrough CNN models that competed and won the ImageNet Large Scale Visual Recognition Challenge in 2021. The model achieved an error of 15.3%, which was greatly better than the runner-up error. The following is an implementation for this CNN."
      ],
      "metadata": {
        "id": "ZV9-zDzs1Qdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet Implementation\n",
        "# Expects input of size 227 at least, for the kernels to work\n",
        "\n",
        "class AlexNet(torch.nn.Module):\n",
        "    def __init__(self, input_height=227, input_width=227, n_classes=26, channels=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the parameters of the model\n",
        "        self.input_height = input_height\n",
        "        self.input_width = input_width\n",
        "        self.n_classes = n_classes\n",
        "        self.channels = channels\n",
        "\n",
        "        # AlexNet Implementation; Same Structure with different outputs die to input\n",
        "        self.model_convolution = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=channels,out_channels=96, kernel_size=11, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=3,stride=2),\n",
        "            nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3, stride=1, padding=1), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "\n",
        "        # The dense network architecture. Assumes input has 4096 nodes, or 4x4x256\n",
        "        self.model_dense = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2), # Regularization\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(4096, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.shape[0], self.channels, self.input_height, self.input_width)\n",
        "        x = self.model_convolution(x)\n",
        "        x = self.model_dense(x)\n",
        "        return x\n",
        "    \n",
        "        "
      ],
      "metadata": {
        "id": "wUn4T3py1Prq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Training, Testing\n",
        "\n",
        "Here, we actually train and test the model on the provided datasets."
      ],
      "metadata": {
        "id": "n6SQFOvF3YGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string\n",
        "\n",
        "import imghdr\n",
        "from PIL import Image\n",
        "from os import listdir"
      ],
      "metadata": {
        "id": "Cz48sIu-5QwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: Path to a folder of .png files. Let #=dataset num, l = letter represented, v=variation, a=augmentation\n",
        "#     Must be structured s.t. hand#_l_v_a.png\n",
        "# Output: List of .png images and their respective labels\n",
        "def loadImages(path):\n",
        "    imagesList = listdir(path)\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for image in imagesList: # iterate over all images in the folder\n",
        "      if imghdr.what(path + image) == 'png':\n",
        "        if (image[6].isalpha()): # 6th position is the letter\n",
        "          img = Image.open(path + image)\n",
        "          imgs.append(img)\n",
        "          labels.append(ord(image[6]) - ord('a')) # assumes that filename structure is 'handx_[label]_....'\n",
        "    return imgs, labels\n",
        "\n",
        "# Input: the images list (3 channels), crop size, and resize hyperparameters\n",
        "# Output: a tensor array of all the reshaped + resized images\n",
        "def applyTransforms(imgs, crop_size, resize):\n",
        "  # Define the necessary preprocessing transforms\n",
        "  num_imgs = len(imgs)\n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize(resize), # Hyperparameter\n",
        "    transforms.CenterCrop(crop_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "\n",
        "  # Create tensor array\n",
        "  transforms_array = np.zeros((num_imgs, 3, crop_size, crop_size))\n",
        "  for i in range(num_imgs):\n",
        "    temp = preprocess(imgs[i])\n",
        "    transforms_array[i,:,:,:] = temp\n",
        "  \n",
        "  return transforms_array\n",
        "\n",
        "# Input: an image tensor [num_imgs, channels, x_dim, y_dim], test split, and a batch size\n",
        "# Output: a tensor array of all the reshaped + resized images\n",
        "def train_dev_test_loaders(transforms_array, labels, test_split=0.2, batch_size=4):\n",
        "  ## Create the training dataand trainloader\n",
        "  train_data, dev_data, train_labels, dev_labels = train_test_split(transforms_array, labels, test_size=test_split, random_state=42)\n",
        "\n",
        "  dev_data, test_data, dev_labels, test_labels = train_test_split(dev_data, dev_labels, test_size=0.5, random_state=42)\n",
        "\n",
        "  train_data_and_labels = []\n",
        "  for i in range(len(train_data)):\n",
        "    sample = (torch.Tensor(train_data[i,:,:,:]), train_labels[i])\n",
        "    train_data_and_labels.append(sample)\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_data_and_labels, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "  ## Create the developmental data and devloader\n",
        "  dev_data_and_labels = []\n",
        "  for i in range(len(dev_data)):\n",
        "    sample = (torch.Tensor(dev_data[i,:,:,:]), dev_labels[i])\n",
        "    dev_data_and_labels.append(sample)\n",
        "\n",
        "  devloader = torch.utils.data.DataLoader(dev_data_and_labels, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "  \n",
        "  ## Create the Test data and testloader\n",
        "  test_data_and_labels = []\n",
        "  for i in range(len(test_data)):\n",
        "    sample = (torch.Tensor(test_data[i,:,:,:]), test_labels[i])\n",
        "    test_data_and_labels.append(sample)\n",
        "\n",
        "  testloader = torch.utils.data.DataLoader(test_data_and_labels, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "  \n",
        "  return [train_data, train_labels, trainloader, dev_data, dev_labels, devloader, test_data, test_labels, testloader]\n",
        "\n",
        "# Input: list of .png images, their labels, and other default parameters\n",
        "# Output: None\n",
        "# Plots the image, assumed to be [3, x_dim, y_dim]\n",
        "def test_loader(transforms_array, labels, batch_size=4):\n",
        "  ## Create the testing data and testloader    \n",
        "  test_data_and_labels = []\n",
        "  for i in range(len(transforms_array)):\n",
        "    sample = (torch.Tensor(transforms_array[i,:,:,:]), labels[i])\n",
        "    test_data_and_labels.append(sample)\n",
        "\n",
        "  testloader = torch.utils.data.DataLoader(test_data_and_labels, batch_size=batch_size,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "  return testloader\n"
      ],
      "metadata": {
        "id": "a5XO1rEL3X2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, add a couple of functions for visualizing images"
      ],
      "metadata": {
        "id": "7swAe1c969Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: One normalized image\n",
        "# Output: None\n",
        "# Plots the image, assumed to be [3, x_dim, y_dim]\n",
        "def imshow(img):\n",
        "  # Unnormalize the image before showing!\n",
        "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
        "                                                        std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
        "                                    transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
        "                                                        std = [ 1., 1., 1. ]),\n",
        "                                  ])\n",
        "    img = invTrans(img)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Show number_batches * display_num images\n",
        "def show_true_vs_predicted(testloader, classes, model, num_batches, batch_size):\n",
        "    # print images\n",
        "    dataiter = iter(testloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    imshow(torchvision.utils.make_grid(images))\n",
        "    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(num_batches * batch_size)))\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                                for j in range(num_batches * batch_size)))\n"
      ],
      "metadata": {
        "id": "fp3GJRot7B3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3: ResNet Basis\n",
        "\n",
        "In 2015, the next field-shaking model to be proposed for image classification was ResNet. One major issue for training models with many hidden layers is the vanishing gradient problem. ResNet, through a skip-layer structure, also called an \"identity shortcut connection,\" avoids this problem."
      ],
      "metadata": {
        "id": "jqgJlS6UHd6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use CNN blocks, which are multiple CNNs, multiple times.\n",
        "class CNNblock(nn.Module):\n",
        "    def __init__(self, in_chan, interm_chan, identity_downsample=None, stride=1):\n",
        "        super(CNNblock, self).__init__()\n",
        "        self.expansion = 4 # Hyperparameter for tuning\n",
        "\n",
        "        self.model_convolution = nn.Sequential(\n",
        "            nn.Conv2d(in_chan, interm_chan, kernel_size=1),\n",
        "            nn.BatchNorm2d(interm_chan),\n",
        "            nn.Conv2d(interm_chan, interm_chan, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(interm_chan),\n",
        "            nn.Conv2d(interm_chan, interm_chan * self.expansion, kernel_size=1),\n",
        "            nn.BatchNorm2d(interm_chan * self.expansion),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.model_convolution(x)\n",
        "\n",
        "        # Skip Connection\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.model_convolution = torch.nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.layer1 = self._make_layer(\n",
        "          block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "          block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "          block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "          block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model_convolution(x)\n",
        "      x = self.layer1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = self.layer3(x)\n",
        "      x = self.layer4(x)\n",
        "\n",
        "      x = self.avgpool(x)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      x = self.fc(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "      identity_downsample = None\n",
        "      layers = []\n",
        "\n",
        "      # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "      # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "      # to the layer that's ahead\n",
        "\n",
        "      if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "        identity_downsample = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channels, intermediate_channels * 4, kernel_size=1, stride=stride),\n",
        "          nn.BatchNorm2d(intermediate_channels * 4),\n",
        "        )\n",
        "        layers.append(\n",
        "          block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "      # The expansion size is always 4 for ResNet 50,101,152\n",
        "      self.in_channels = intermediate_channels * 4\n",
        "\n",
        "      # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "      # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "      # and also same amount of channels.\n",
        "      \n",
        "      for i in range(num_residual_blocks - 1):\n",
        "        layers.append(block(self.in_channels, intermediate_channels))\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "  return ResNet(CNNblock, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "def test():\n",
        "    net = ResNet50(img_channel=3, num_classes=1000)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
        "    print(y.size())\n",
        "\n",
        "test()\n"
      ],
      "metadata": {
        "id": "qJb-htLAHnll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Inception\n",
        "\n"
      ],
      "metadata": {
        "id": "gVzgNCJjS0ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RDw21sE9S0Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Citations:\n",
        "\n",
        "ResNet:\n",
        "https://www.analyticsvidhya.com/blog/2021/06/build-resnet-from-scratch-with-python/\n",
        "\n"
      ],
      "metadata": {
        "id": "46ykaTG2Jr9l"
      }
    }
  ]
}