{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_FinalProject_Submission.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJh5IQdFoZW19r25528tCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swadhwa5/MLFinalProject/blob/main/ML_FinalProject_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Final Project\n",
        "By: Shreya Wadhwa, Alan Zhang, Aidan Aug, Trisha Karani\n",
        "JHED: swadhwa, azhang, tkarani1, aaug1\n",
        "\n",
        "*Due: April 28th, 2022*"
      ],
      "metadata": {
        "id": "PAG0pquLrTt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:**\n",
        "\n",
        "This is the iPython/Jupyter Notebook for our Machine Learning Final Project. For this project, we decided to develop a Majority Vote classifer model over three different CNNs to train a model to recognize sign language letters. The project into the following sections:\n",
        "\n",
        "1. Required Packages for Running the Notebook\n",
        "\n",
        "2. Data Augmentation\n",
        "\n",
        "3. Model Implementation\n",
        "\n",
        "4. Model Training and Testing\n",
        "\n",
        "5. Conclusions and Future Works"
      ],
      "metadata": {
        "id": "uJwT7uddrzCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 Python Packages:\n",
        "\n",
        "This section is simply a compilation of all the required packages for every section in the notebook. Please make sure to run this prior to any of the other code sections."
      ],
      "metadata": {
        "id": "LmaqcEJXspEJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIKJRQF6n6J0"
      },
      "outputs": [],
      "source": [
        "## Data Processing, Augmentation, and Feature Engineering:\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image, ImageEnhance\n",
        "from os import listdir\n",
        "import imghdr\n",
        "import skimage\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "\n",
        "## Model Implementation\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import skimage\n",
        "from skimage.transform import rotate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Data Augmentation and Feature Engineering\n",
        "\n",
        "For Data Augmentation, we decided to increase our dataset via the following processes:\n",
        "1. Blur\n",
        "2. Brighten\n",
        "3. Rotate\n",
        "4. Translate\n",
        "5. Zoom"
      ],
      "metadata": {
        "id": "MVEhis2gTfRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Model Implementation\n",
        "\n",
        "For our model, we decided to implement a majority vote classifier based on three Convolutional Neural Networks, each with differing structures. Each model structure has basis in other current models."
      ],
      "metadata": {
        "id": "u_uiqA9Jr35T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: AlexNet\n",
        "\n",
        "AlexNet was one of the breakthrough CNN models that competed and won the ImageNet Large Scale Visual Recognition Challenge in 2021. The model achieved an error of 15.3%, which was greatly better than the runner-up error. The following is an implementation for this CNN."
      ],
      "metadata": {
        "id": "mnGXysz-HVo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(torch.nn.Module):\n",
        "    ### TODO Implement your model's structure and input/filter/output dimensions\n",
        "    def __init__(self, input_height=600, input_width=600, n_classes=27):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the parameters of the model\n",
        "        self.input_height = input_height\n",
        "        self.input_width = input_width\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # AlexNet Implementation; Same Structure with different outputs die to input\n",
        "        self.model_convolution = nn.Sequential(\n",
        "            # INPUT: 600x600x3\n",
        "            nn.Conv2d(in_channels=3,out_channels=96, kernel_size=12, stride=4), # output: 148x148\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=4, stride=2), #73x73\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5, pad=2), #73x73\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(3,3), #36x36\n",
        "            nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3, pad=1), #36x36\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3, pad=1), #36x36\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3, pad=1), #36x36\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size=6,stride=2), #16x16x256\n",
        "            nn.Conv2d(256,256, 12, padding=1, stride=2) #4x4x256\n",
        "        )\n",
        "\n",
        "        # The dense network architecture. Assumes input has 4096 nodes, or 4x4x256\n",
        "        self.model_dense = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(1000, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ### TODO Implement your best model's forward pass module    \n",
        "        # Reshape back into 28 x 28\n",
        "        x = x.reshape(x.shape[0], self.input_height, self.input_width)\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "        x = self.model_convolution(x)\n",
        "        x = self.model_dense(x)\n",
        "        return x\n",
        "    \n",
        "        "
      ],
      "metadata": {
        "id": "x93d1hsRovKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: ResNet Basis\n",
        "\n",
        "In 2015, the next field-shaking model to be proposed for image classification was ResNet. One major issue for training models with many hidden layers is the vanishing gradient problem. ResNet, through a skip-layer structure, also called an \"identity shortcut connection,\" avoids this problem."
      ],
      "metadata": {
        "id": "jqgJlS6UHd6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use CNN blocks, which are multiple CNNs, multiple times.\n",
        "class CNNblock(nn.Module):\n",
        "    def __init__(self, in_chan, interm_chan, identity_downsample=None, stride=1):\n",
        "        super(CNNblock, self).__init__()\n",
        "        self.expansion = 4 # Hyperparameter for tuning\n",
        "\n",
        "        self.model_convolution = nn.Sequential(\n",
        "            nn.Conv2d(in_chan, interm_chan, kernel_size=1),\n",
        "            nn.BatchNorm2d(interm_chan),\n",
        "            nn.Conv2d(interm_chan, interm_chan, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(interm_chan),\n",
        "            nn.Conv2d(interm_chan, interm_chan * self.expansion, kernel_size=1),\n",
        "            nn.BatchNorm2d(interm_chan * self.expansion),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "        x = self.model_convolution(x)\n",
        "\n",
        "        # Skip Connection\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.model_convolution = torch.nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.layer1 = self._make_layer(\n",
        "          block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "          block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "          block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "          block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model_convolution(x)\n",
        "      x = self.layer1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = self.layer3(x)\n",
        "      x = self.layer4(x)\n",
        "\n",
        "      x = self.avgpool(x)\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      x = self.fc(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "      identity_downsample = None\n",
        "      layers = []\n",
        "\n",
        "      # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "      # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "      # to the layer that's ahead\n",
        "\n",
        "      if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "        identity_downsample = nn.Sequential(\n",
        "          nn.Conv2d(self.in_channels, intermediate_channels * 4, kernel_size=1, stride=stride),\n",
        "          nn.BatchNorm2d(intermediate_channels * 4),\n",
        "        )\n",
        "        layers.append(\n",
        "          block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "      # The expansion size is always 4 for ResNet 50,101,152\n",
        "      self.in_channels = intermediate_channels * 4\n",
        "\n",
        "      # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "      # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "      # and also same amount of channels.\n",
        "      \n",
        "      for i in range(num_residual_blocks - 1):\n",
        "        layers.append(block(self.in_channels, intermediate_channels))\n",
        "      return nn.Sequential(*layers)\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "  return ResNet(CNNblock, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "def test():\n",
        "    net = ResNet50(img_channel=3, num_classes=1000)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
        "    print(y.size())\n",
        "\n",
        "test()\n"
      ],
      "metadata": {
        "id": "qJb-htLAHnll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Inception\n",
        "\n"
      ],
      "metadata": {
        "id": "gVzgNCJjS0ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RDw21sE9S0Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Citations:\n",
        "\n",
        "ResNet:\n",
        "https://www.analyticsvidhya.com/blog/2021/06/build-resnet-from-scratch-with-python/\n",
        "\n"
      ],
      "metadata": {
        "id": "46ykaTG2Jr9l"
      }
    }
  ]
}