{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swadhwa5/MLFinalProject/blob/main/ML_FinalProject_Submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAG0pquLrTt3"
   },
   "source": [
    "# Machine Learning Final Project\n",
    "By: Shreya Wadhwa, Alan Zhang, Aidan Aug, Trisha Karani\n",
    "JHED: swadhwa, azhang, tkarani1, aaug1\n",
    "\n",
    "*Due: April 28th, 2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJwT7uddrzCU"
   },
   "source": [
    "**Description:**\n",
    "\n",
    "This is the iPython/Jupyter Notebook for our Machine Learning Final Project. For this project, we decided to develop a Majority Vote classifer model over three different CNNs to train a model to recognize sign language letters. The project into the following sections:\n",
    "\n",
    "1. Required Packages for Running the Notebook\n",
    "\n",
    "2. Data Augmentation\n",
    "\n",
    "3. Model Implementation\n",
    "\n",
    "4. Model Training and Testing\n",
    "\n",
    "5. Conclusions and Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmaqcEJXspEJ"
   },
   "source": [
    "## Part 1 Python Packages:\n",
    "\n",
    "This section is simply a compilation of all the required packages for every section in the notebook. Please make sure to run this prior to any of the other code sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIKJRQF6n6J0"
   },
   "outputs": [],
   "source": [
    "## Data Processing, Augmentation, and Feature Engineering:\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageEnhance\n",
    "from os import listdir\n",
    "import imghdr\n",
    "import skimage\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "\n",
    "## Model Implementation\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import skimage\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVEhis2gTfRb"
   },
   "source": [
    "## Part 2: Data Augmentation and Feature Engineering\n",
    "\n",
    "For Data Augmentation, we decided to increase our dataset via the following processes:\n",
    "1. Blur\n",
    "2. Brighten\n",
    "3. Rotate\n",
    "4. Translate\n",
    "5. Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fc-uo79W01LN"
   },
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    imagesList = listdir(path)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for image in imagesList:\n",
    "      if imghdr.what(path + image) == 'png':\n",
    "        if (image[6].isalpha()): # only add 5 of each image, only add alphabetical values\n",
    "          img = Image.open(path + image)\n",
    "          imgs.append(img)\n",
    "          labels.append(ord(image[6]) - ord('a')) # assumes that filename structure is 'handx_[label]_....'\n",
    "    return imgs, labels\n",
    "\n",
    "# Convert png img array to array np arrays\n",
    "# Input: PNG image array\n",
    "# Output: a list of numpy images\n",
    "# Works?: Yes\n",
    "def ImagesToArray(imgs):\n",
    "  imgs_array = []\n",
    "  for img in imgs:\n",
    "    img_array = np.array(img)\n",
    "    imgs_array.append(img_array)\n",
    "  return imgs_array\n",
    "\n",
    "# Zero pad all images\n",
    "# Input: list of numpy images\n",
    "# Output: numpy array of N 600x600 images with 3 channels\n",
    "# Works?: Yes, but might not be necessary\n",
    "def shape600(x):\n",
    "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
    "  for i, img in enumerate(x):\n",
    "    x_pad_width = (600 - img.shape[0])//2\n",
    "    y_pad_width = (600 - img.shape[1])//2\n",
    "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
    "  return reshaped_array\n",
    "\n",
    "# Normalizes images... based on... what?\n",
    "# Input: image array\n",
    "# Output: a list of numpy arrays\n",
    "# Works?: ??? Not entirely sure if this is the correct method though, based on online implementations of AlexNet\n",
    "def Normalize(imgs):\n",
    "  new_imgs = []\n",
    "  for img in imgs:\n",
    "      # flat_img = img.flatten()\n",
    "      m = np.mean(img)\n",
    "      std = np.std(img)\n",
    "      img = (img-m)/std\n",
    "      new_imgs.append(img)\n",
    "  return new_imgs\n",
    "\n",
    "################### DATA AUGMENTATION ######################\n",
    "# x is input image, sd is how much to blur\n",
    "def blur(imgs, sd=1):\n",
    "  filtered_img = np.zeros((imgs.shape[0], 600, 600, 3))\n",
    "  for i in range(imgs.shape[0]):\n",
    "    filtered_img[i,:,:,:] = skimage.filters.gaussian(imgs[i,:,:,:], sigma=sd)\n",
    "    #filtered_img.save('./Filter_gaussian/img_' + i + '_gaussianfilt.png')\n",
    "  return filtered_img\n",
    "\n",
    "def Scale(imgs):\n",
    "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
    "  for i, img in enumerate(imgs):\n",
    "    # ratio = random.randrange(.2, .5, .1)\n",
    "    ratio = random.choice([0.1, 0.2, 0.3, 0.4])\n",
    "    x = int(ratio * 600 / 2)\n",
    "    scaled = img[x:600-x, x:600-x]\n",
    "    # scaled = cv2.imread(scaled)\n",
    "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
    "    scaled_images[i] = res\n",
    "  return scaled_images\n",
    "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
    "\n",
    "def Rotate30(imgs): \n",
    "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_dir = random.choice([-1, 1])\n",
    "    new_img = rotate(img, rand_dir * 30) \n",
    "    rot30_imgs[i, :] = new_img\n",
    "  return rot30_imgs\n",
    "\n",
    "def VerticalFlip(imgs): \n",
    "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    new_img = np.fliplr(img)\n",
    "    flip_imgs[i, :, :, :] = new_img\n",
    "  return flip_imgs\n",
    "\n",
    "def Translation(imgs): \n",
    "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_x = random.randrange(-150, 150, 50)\n",
    "    rand_y = random.randrange(-150, 150, 50)\n",
    "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
    "    new_img = warp(img,transform, mode=\"constant\")  \n",
    "    trans_imgs[i, :] = new_img\n",
    "  return trans_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_uiqA9Jr35T"
   },
   "source": [
    "## Part 3: Model Implementation\n",
    "\n",
    "For our model, we decided to implement a majority vote classifier based on three Convolutional Neural Networks, each with differing structures. Each model structure has basis in other current models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnGXysz-HVo0"
   },
   "source": [
    "### Model 1: LeNet with 3 Channels\n",
    "\n",
    "LeNet was one of the first convolutional neural network (CNN) models used on 28x28 black and white images. While it is simple, it was one of the first uses of the backpropgation algorithm in practical applications: specifically, reading handwritten numbers. In 1990, there was an error rate of 1% and rejection rate of about 9%. The model structure is as follows:\n",
    "1. 2 convolutional layers\n",
    "2. 2 pooling layers\n",
    "3. 3 fully-connected\n",
    "\n",
    "In this implementation, we make slight modifications to this network and apply it to RGB images.\n",
    "\n",
    "LeCun, Y.; Boser, B.; Denker, J. S.; Henderson, D.; Howard, R. E.; Hubbard, W. & Jackel, L. D. (1989). Backpropagation applied to handwritten zip code recognition. Neural Computation, 1(4):541-551.[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7IIrTDx25FL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HUiuN6C2kJm"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZV9-zDzs1Qdi"
   },
   "source": [
    "### Model 2: AlexNet\n",
    "\n",
    "AlexNet was one of the breakthrough CNN models that competed and won the ImageNet Large Scale Visual Recognition Challenge in 2021. The model achieved an error of 15.3%, which was greatly better than the runner-up error. The following is an implementation for this CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUn4T3py1Prq"
   },
   "outputs": [],
   "source": [
    "# AlexNet Implementation\n",
    "# Expects input of size 227 at least, for the kernels to work\n",
    "\n",
    "class AlexNet(torch.nn.Module):\n",
    "    def __init__(self, input_height=227, input_width=227, n_classes=26, channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the parameters of the model\n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.n_classes = n_classes\n",
    "        self.channels = channels\n",
    "\n",
    "        # AlexNet Implementation; Same Structure with different outputs die to input\n",
    "        self.model_convolution = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=channels,out_channels=96, kernel_size=11, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=96,out_channels=256,kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(in_channels=256,out_channels=384,kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384,out_channels=384,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        # The dense network architecture. Assumes input has 4096 nodes, or 4x4x256\n",
    "        self.model_dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2), # Regularization\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(4096, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], self.channels, self.input_height, self.input_width)\n",
    "        x = self.model_convolution(x)\n",
    "        x = self.model_dense(x)\n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKm-gz-diPvj"
   },
   "source": [
    "### Additional Functions Related to Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3IxBNSViKbt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def accuracy(y : np.ndarray, y_hat : np.ndarray) -> np.float64:\n",
    "    \"\"\"Calculate the simple accuracy given two numpy vectors, each with int values\n",
    "    corresponding to each class.\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): actual value\n",
    "        y_hat (np.ndarray): predicted value\n",
    "\n",
    "    Returns:\n",
    "        np.float64: accuracy\n",
    "    \"\"\"\n",
    "    N = len(y)   \n",
    "    number_correct = N - np.count_nonzero(y - y_hat)\n",
    "    accuracy = number_correct / N\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def approx_train_acc_and_loss(model, train_data : np.ndarray, train_labels : np.ndarray) -> np.float64:\n",
    "    \"\"\"Given a model, training data and its associated labels, calculate the simple accuracy when the \n",
    "    model is applied to the training dataset.\n",
    "    This function is meant to be run during training to evaluate model training accuracy during training.\n",
    "\n",
    "    Args:\n",
    "        model (pytorch model): model class object.\n",
    "        train_data (np.ndarray): training data\n",
    "        train_labels (np.ndarray): training labels\n",
    "\n",
    "    Returns:\n",
    "        np.float64: simple accuracy\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(train_data), 1, replace=False)\n",
    "    x = torch.from_numpy(train_data[idxs].astype(np.float32))\n",
    "    y = torch.from_numpy(train_labels[idxs])\n",
    "    if torch.cuda.is_available():\n",
    "      x = x.cuda()\n",
    "      y = y.cuda()\n",
    "      \n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    y_pred = torch.max(logits, 1)[1]\n",
    "    return accuracy(train_labels[idxs], y_pred.cpu().numpy()), loss.item()\n",
    "\n",
    "\n",
    "def dev_acc_and_loss(model, dev_data : np.ndarray, dev_labels : np.ndarray) -> np.float64:\n",
    "    \"\"\"Given a model, a validation dataset and its associated labels, calcualte the simple accuracy when the\n",
    "    model is applied to the validation dataset.\n",
    "    This function is meant to be run during training to evaluate model validation accuracy.\n",
    "\n",
    "    Args:\n",
    "        model (pytorch model): model class obj\n",
    "        dev_data (np.ndarray): validation data\n",
    "        dev_labels (np.ndarray): validation labels\n",
    "\n",
    "    Returns:\n",
    "        np.float64: simple validation accuracy\n",
    "    \"\"\"\n",
    "    dev_labels = np.asarray(dev_labels)\n",
    "\n",
    "    x = torch.from_numpy(dev_data.astype(np.float32))\n",
    "    y = torch.from_numpy(dev_labels.astype(int))\n",
    "    if torch.cuda.is_available():\n",
    "      x = x.cuda()\n",
    "      y = y.cuda()\n",
    "    logits = model(x)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    y_pred = torch.max(logits, 1)[1]\n",
    "    y_pred = y_pred.cpu()\n",
    "    return accuracy(dev_labels, y_pred.numpy()), loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YH83vLphetj"
   },
   "outputs": [],
   "source": [
    "# Train the model parameters\n",
    "def train_model(trainloader, train_data, train_labels, dev_data, dev_labels, criterion, optimizer, model, num_images, n=20):\n",
    "\n",
    "  for epoch in range(n):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        train_acc, train_loss = approx_train_acc_and_loss(model, train_data, train_labels)\n",
    "        dev_acc, dev_loss = dev_acc_and_loss(model, dev_data, dev_labels)\n",
    "        step_metrics = {\n",
    "                'step': epoch, \n",
    "                'train_loss': loss.item(), \n",
    "                'train_acc': train_acc,\n",
    "                'dev_loss': dev_loss,\n",
    "                'dev_acc': dev_acc\n",
    "            }\n",
    "\n",
    "        print(f\"On step {epoch}:\\tTrain loss {train_loss}\\t|\\tDev acc is {dev_acc}\")\n",
    "\n",
    "  print('Finished Training')\n",
    "\n",
    "# # Test the model on help out dev set\n",
    "# def test_model(testloader, labels1, test_data, model):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     misclass_ind = []\n",
    "#     incorrect_imgs = []\n",
    "#     incorrect_labels = []\n",
    "#     predicted_labels = []\n",
    "#     # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "#     with torch.no_grad():\n",
    "#         for data in testloader:\n",
    "#             images, labels = data\n",
    "#             if torch.cuda.is_available():\n",
    "#               images = images.cuda()\n",
    "#               labels = labels.cuda()\n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs = model(images)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             correct += (predicted == labels).sum().item() # Calculate number correct\n",
    "#             if ((predicted != labels).sum().item()) > 0:\n",
    "#                 incorrect = predicted - labels\n",
    "#                 for i in range(len(incorrect)):\n",
    "#                     if incorrect[i] != 0:\n",
    "#                         incorrect_imgs.append(images[i])\n",
    "#                         misclass_ind.append(total + i)\n",
    "#                         incorrect_labels.append(labels1[i + total])\n",
    "#                         predicted_labels.append(predicted[i])\n",
    "\n",
    "                    \n",
    "#             total += labels.size(0) # for each batch (size=4), predict the labels\n",
    "\n",
    "#     print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')\n",
    "#     incorrect_images = test_data[misclass_ind]\n",
    "#     imshow(torchvision.utils.make_grid(incorrect_imgs))\n",
    "#     print(\"Actual labels: \" +\n",
    "#           ' '.join(f'{classes[incorrect_labels[j]]:5s}' for j in range(len(incorrect_labels))))\n",
    "#     print(\"predicted labels: \" +\n",
    "#           ' '.join(f'{classes[predicted[j]]:5s}' for j in range(len(incorrect_labels))))\n",
    "\n",
    "#     return correct, total, misclass_ind\n",
    "\n",
    "# Test the model on help out dev set\n",
    "def test_model(testloader, labels1, test_data, model, num_display=0):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    misclass_ind = []\n",
    "    incorrect_imgs = []\n",
    "    incorrect_labels = []\n",
    "    predicted_labels = []\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            if torch.cuda.is_available():\n",
    "              images = images.cuda()\n",
    "              labels = labels.cuda()\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item() # Calculate number correct\n",
    "            if ((predicted != labels).sum().item()) > 0:\n",
    "                incorrect = predicted - labels\n",
    "                for i in range(len(incorrect)):\n",
    "                    if incorrect[i] != 0:\n",
    "                        incorrect_imgs.append(images[i])\n",
    "                        misclass_ind.append(total + i)\n",
    "                        incorrect_labels.append(labels1[i + total])\n",
    "                        predicted_labels.append(predicted[i])\n",
    "\n",
    "                    \n",
    "            total += labels.size(0) # for each batch (size=4), predict the labels\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct // total} %')\n",
    "    incorrect_images = torch.Tensor(test_data[misclass_ind]).cpu()\n",
    "    incorrect_images = incorrect_images[0:num_display]\n",
    "    imshow(torchvision.utils.make_grid(incorrect_imgs))\n",
    "    print(\"Actual labels: \" +\n",
    "          ' '.join(f'{classes[incorrect_labels[j]]:5s}' for j in range(num_display)))\n",
    "    print(\"predicted labels: \" +\n",
    "          ' '.join(f'{classes[predicted_labels[j]]:5s}' for j in range(num_display)))\n",
    "\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zNMf-hSjCvV"
   },
   "outputs": [],
   "source": [
    "# Input: One normalized image\n",
    "# Output: None\n",
    "# Plots the image, assumed to be [3, x_dim, y_dim]\n",
    "def imshow(img):\n",
    "  # Unnormalize the image before showing!\n",
    "    invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                        std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                    transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                        std = [ 1., 1., 1. ]),\n",
    "                                  ])\n",
    "    img = invTrans(img.cpu())\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Visualize how some of the images look after processing the data\n",
    "def visualize_images(trainloader, num_display, batch_size, xdim, ydim):\n",
    "    dataiter = iter(trainloader)\n",
    "    images = torch.empty((num_display * batch_size, channels, xdim, ydim))\n",
    "    labels = torch.empty((num_display * batch_size), dtype=torch.uint8)\n",
    "    #images, labels = dataiter.next()\n",
    "\n",
    "    start_index = 0\n",
    "    stop_index = batch_size\n",
    "    for i in range(num_display):\n",
    "        image, label = dataiter.next()\n",
    "        images[start_index:stop_index, :, :, :] = image\n",
    "        labels[start_index:stop_index] = label\n",
    "        start_index = stop_index\n",
    "        stop_index += batch_size\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    # print labels\n",
    "    print(\"labels: \" +\n",
    "          ' '.join(f'{classes[labels[j]]:5s}' for j in range(num_display * batch_size)))\n",
    "\n",
    "\n",
    "\n",
    "# Show number_batches * display_num images\n",
    "def show_true_vs_predicted(testloader, classes, model, num_batches, batch_size):\n",
    "    # print images\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(num_batches * batch_size)))\n",
    "\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                                for j in range(num_batches * batch_size)))\n",
    "\n",
    "\n",
    "# def show_incorrect(misclass_ind, images, labels, model, num_display=1):\n",
    "#     if (len(misclass_ind) != 0):\n",
    "#       print(type(labels))\n",
    "#       incorrect_imgs = torch.Tensor(images[misclass_ind])\n",
    "#       true_labels = labels[misclass_ind]\n",
    "#       if torch.cuda.is_available():\n",
    "#         incorrect_imgs = incorrect_imgs.cuda()\n",
    "        \n",
    "#         model = model.to(\"cuda\")\n",
    "      \n",
    "\n",
    "#       outputs = model(incorrect_imgs)\n",
    "#       _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "#       idxs = np.random.choice(len(incorrect_imgs), num_display)\n",
    "\n",
    "#       incorrect_imgs = incorrect_imgs.cpu()\n",
    "#       # true_labels = true_labels[idxs]\n",
    "#       # predicted = predicted[idxs]\n",
    "\n",
    "#       imshow(torchvision.utils.make_grid(incorrect_imgs))\n",
    "#       print(\"Actual labels: \" +\n",
    "#             ' '.join(f'{classes[true_labels[j]]:5s}' for j in range(num_display)))\n",
    "#       print(\"predicted labels: \" +\n",
    "#             ' '.join(f'{classes[predicted[j]]:5s}' for j in range(num_display)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6SQFOvF3YGC"
   },
   "source": [
    "## Part 4: Training, Testing\n",
    "\n",
    "Here, we actually train and test the model on the provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz48sIu-5QwL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "import imghdr\n",
    "from PIL import Image\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5XO1rEL3X2B"
   },
   "outputs": [],
   "source": [
    "# Input: Path to a folder of .png files. Let #=dataset num, l = letter represented, v=variation, a=augmentation\n",
    "#     Must be structured s.t. hand#_l_v_a.png\n",
    "# Output: List of .png images and their respective labels\n",
    "def loadImages(path):\n",
    "    imagesList = listdir(path)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for image in imagesList: # iterate over all images in the folder\n",
    "      if imghdr.what(path + image) == 'png':\n",
    "        if (image[6].isalpha()): # 6th position is the letter\n",
    "          img = Image.open(path + image)\n",
    "          imgs.append(img)\n",
    "          labels.append(ord(image[6]) - ord('a')) # assumes that filename structure is 'handx_[label]_....'\n",
    "    return imgs, labels\n",
    "\n",
    "# Input: the images list (3 channels), crop size, and resize hyperparameters\n",
    "# Output: a tensor array of all the reshaped + resized images\n",
    "def applyTransforms(imgs, crop_size, resize):\n",
    "  # Define the necessary preprocessing transforms\n",
    "  num_imgs = len(imgs)\n",
    "  preprocess = transforms.Compose([\n",
    "    transforms.Resize(resize), # Hyperparameter\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  # Create tensor array\n",
    "  transforms_array = np.zeros((num_imgs, 3, crop_size, crop_size))\n",
    "  for i in range(num_imgs):\n",
    "    temp = preprocess(imgs[i])\n",
    "    transforms_array[i,:,:,:] = temp\n",
    "  \n",
    "  return transforms_array\n",
    "\n",
    "# Input: list of .png images, their labels, and other default parameters\n",
    "# Output: None\n",
    "# Plots the image, assumed to be [3, x_dim, y_dim]\n",
    "def test_loader(test_data, test_labels, batch_size=4):\n",
    "    # Create the testing data and testloader    \n",
    "    test_data_and_labels = []\n",
    "    for i in range(len(test_data)):\n",
    "        sample = (torch.Tensor(test_data[i, :, :, :]), test_labels[i])\n",
    "        test_data_and_labels.append(sample)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(test_data_and_labels, batch_size=batch_size,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    test_labels = np.asarray(test_labels)\n",
    "    return test_data, test_labels, testloader\n",
    "\n",
    "# Input: an image tensor [num_imgs, channels, x_dim, y_dim], test split, and a batch size\n",
    "# Output: a tensor array of all the reshaped + resized images\n",
    "def train_dev_test_loaders(transforms_array, labels, test_split=0.2, batch_size=4):\n",
    "  ## Create the training dataand trainloader\n",
    "  train_data, dev_data, train_labels, dev_labels = train_test_split(transforms_array, labels, test_size=test_split, random_state=42)\n",
    "\n",
    "  dev_data, test_data, dev_labels, test_labels = train_test_split(dev_data, dev_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "  train_data_and_labels = []\n",
    "  for i in range(len(train_data)):\n",
    "    sample = (torch.Tensor(train_data[i,:,:,:]), train_labels[i])\n",
    "    train_data_and_labels.append(sample)\n",
    "\n",
    "  trainloader = torch.utils.data.DataLoader(train_data_and_labels, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "\n",
    "  ## Create the developmental data and devloader\n",
    "  dev_data_and_labels = []\n",
    "  for i in range(len(dev_data)):\n",
    "    sample = (torch.Tensor(dev_data[i,:,:,:]), dev_labels[i])\n",
    "    dev_data_and_labels.append(sample)\n",
    "\n",
    "  devloader = torch.utils.data.DataLoader(dev_data_and_labels, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "  \n",
    "  ## Create the Test data and testloader\n",
    "  test_data_and_labels = []\n",
    "  for i in range(len(test_data)):\n",
    "    sample = (torch.Tensor(test_data[i,:,:,:]), test_labels[i])\n",
    "    test_data_and_labels.append(sample)\n",
    "\n",
    "  testloader = torch.utils.data.DataLoader(test_data_and_labels, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "  train_labels = np.asarray(train_labels)\n",
    "  dev_labels = np.asarray(dev_labels)\n",
    "  test_labels = np.asarray(test_labels)\n",
    "  return [train_data, train_labels, trainloader, dev_data, dev_labels, devloader, test_data, test_labels, testloader]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQgTPlW_hFcc"
   },
   "source": [
    "### LeNet: Training, Testing, and Analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNRTvo4kx5_0"
   },
   "source": [
    "Step 1: First, we load in our datasets and apply the necessary transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kGLmfi2gSsx"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "orig_data_path = \"/content/drive/MyDrive/Machine_Learning_Datasets/Data_full/\"\n",
    "aug_data_path = \"/content/drive/MyDrive/Machine_Learning_Datasets/FinalImages/\"\n",
    "mult_augments_path = \"/content/drive/MyDrive/Machine_Learning_Datasets/Only_Mult_Augments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRwv_bR6iklq"
   },
   "outputs": [],
   "source": [
    "### Get all the datasets\n",
    "\n",
    "orig_imgs, orig_labels = loadImages(orig_data_path)\n",
    "aug_imgs, aug_labels = loadImages(aug_data_path)\n",
    "mult_aug_imgs, mult_aug_labels = loadImages(mult_augments_path)\n",
    "\n",
    "print(f\"Total number of images in Orig Dataset is: {len(orig_imgs)}\")\n",
    "print(f\"Total number of images in Aug Dataset is: {len(aug_imgs)}\")\n",
    "print(f\"Total number of images in Mult_Aug Dataset is: {len(mult_aug_imgs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4pIMLJRjb-r"
   },
   "outputs": [],
   "source": [
    "### Add additional comments for LeNet\n",
    "batch_size = 4\n",
    "channels = 3\n",
    "xdim = 32\n",
    "ydim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHmZNSbejuZC"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data to feed into LeNet 32x32\n",
    "transforms_array = applyTransforms(orig_imgs, crop_size=32, resize=15)\n",
    "[train_data, train_labels, trainloader, dev_data, dev_labels, devloader, \n",
    " test_data, test_labels, testloader] = train_dev_test_loaders(transforms_array, orig_labels, test_split=0.2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBwHyzMVjSJx"
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "classes = list(string.ascii_uppercase) # A-Z\n",
    "lenet_no_aug = LeNet(len(classes))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet_no_aug.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(lenet_no_aug.parameters(), lr=lr, momentum=0.9)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lenet_no_aug.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pacxS04ykAt8"
   },
   "outputs": [],
   "source": [
    "train_model(trainloader, train_data, train_labels, dev_data, dev_labels, criterion, optimizer, lenet_no_aug, num_images=len(train_data), n=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDEKoTuQx_vx"
   },
   "outputs": [],
   "source": [
    "print(\"Evalating on the held-out test set...\")\n",
    "correct, total = test_model(testloader, test_labels, test_data, lenet_no_aug)\n",
    "print(f\"Correct: {correct} \\nTotal: {total}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VS8LILIzoAN"
   },
   "outputs": [],
   "source": [
    "# Save the model!\n",
    "torch.save(lenet_no_aug.state_dict(), \"/content/drive/MyDrive/Machine_Learning_Datasets/models/lenet_no_aug_650\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvAGL9PVzr5J"
   },
   "source": [
    "#### Now, apply the same process on the Data-Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FM9IOcaUzpFv"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data to feed into LeNet 32x32\n",
    "transforms_array = applyTransforms(aug_imgs, crop_size=32, resize=35)\n",
    "[train_data, train_labels, trainloader, dev_data, dev_labels, devloader, \n",
    " test_data, test_labels, testloader] = train_dev_test_loaders(transforms_array, aug_labels, test_split=0.2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEEQLulhz-Xe"
   },
   "outputs": [],
   "source": [
    "# Step 4: Declare the loss function and optimizer for training\n",
    "\n",
    "lr = 0.001  # Too large suboptimal convergence. Too small is process gets stuck. Find a balance\n",
    "lenet_with_aug = LeNet(len(classes))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet_with_aug.parameters(), lr=lr)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lenet_with_aug.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cANz5UEh0CAz"
   },
   "outputs": [],
   "source": [
    "train_model(trainloader, train_data, train_labels, dev_data, dev_labels, criterion, optimizer,\n",
    "            lenet_with_aug, num_images=len(train_data), n=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTWzXQVu0Dnd"
   },
   "outputs": [],
   "source": [
    "print(\"Evalating on the held-out test set...\")\n",
    "correct, total = test_model(testloader, test_labels, test_data, lenet_with_aug, num_display=10)\n",
    "print(f\"Correct: {correct} \\nTotal: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5AkBFpa0nuo"
   },
   "outputs": [],
   "source": [
    "# Save the model!\n",
    "torch.save(lenet_with_aug.state_dict(), \"/content/drive/MyDrive/Machine_Learning_Datasets/models/lenet_with_aug_3900\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncg9CrT00rLv"
   },
   "source": [
    "#### Compare the performance on some \"real-world\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKroz9kf0vNl"
   },
   "outputs": [],
   "source": [
    "transforms_array_test_data = applyTransforms(mult_aug_imgs, crop_size=32, resize=35)\n",
    "test_data, test_labels, testloader = test_loader(transforms_array_test_data, mult_aug_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJh4ait70xcz"
   },
   "outputs": [],
   "source": [
    "# Step 1: Visualize how some of the images look after processing the data\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(\"labels: \" + ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaeXgHfO0zD7"
   },
   "outputs": [],
   "source": [
    "# Let's use the no augmentation to observe training time\n",
    "lenet_no_aug = LeNet(len(classes))\n",
    "lenet_no_aug.load_state_dict(torch.load(\"/content/drive/MyDrive/Machine_Learning_Datasets/models/lenet_no_aug_650\"))\n",
    "lenet_no_aug.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lenet_no_aug.to(device);\n",
    "\n",
    "correct, total = test_model(testloader, test_labels, test_data, lenet_no_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzta-84O04jy"
   },
   "outputs": [],
   "source": [
    "lenet_with_aug = LeNet(len(classes))\n",
    "lenet_with_aug.load_state_dict(torch.load(\"/content/drive/MyDrive/Machine_Learning_Datasets/models/lenet_with_aug_3900\"))\n",
    "lenet_with_aug.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lenet_with_aug.to(device);\n",
    "\n",
    "correct, total = test_model(testloader, test_labels, test_data, lenet_with_aug)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7THaEpzn1ahN"
   },
   "source": [
    "### AlexNet: Training, Testing, and Analysis!\n",
    "\n",
    "Same process, but now with alexnet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaAXAb1d1Z3i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeiOeTRa1YiJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqgJlS6UHd6M"
   },
   "source": [
    "#Model 3: ResNet Basis\n",
    "\n",
    "In 2015, the next field-shaking model to be proposed for image classification was ResNet. One major issue for training models with many hidden layers is the vanishing gradient problem. ResNet, through a skip-layer structure, also called an \"identity shortcut connection,\" avoids this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJb-htLAHnll"
   },
   "outputs": [],
   "source": [
    "# We use CNN blocks, which are multiple CNNs, multiple times.\n",
    "class CNNblock(nn.Module):\n",
    "    def __init__(self, in_chan, interm_chan, identity_downsample=None, stride=1):\n",
    "        super(CNNblock, self).__init__()\n",
    "        self.expansion = 4 # Hyperparameter for tuning\n",
    "\n",
    "        self.model_convolution = nn.Sequential(\n",
    "            nn.Conv2d(in_chan, interm_chan, kernel_size=1),\n",
    "            nn.BatchNorm2d(interm_chan),\n",
    "            nn.Conv2d(interm_chan, interm_chan, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(interm_chan),\n",
    "            nn.Conv2d(interm_chan, interm_chan * self.expansion, kernel_size=1),\n",
    "            nn.BatchNorm2d(interm_chan * self.expansion),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.model_convolution(x)\n",
    "\n",
    "        # Skip Connection\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.model_convolution = torch.nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.layer1 = self._make_layer(\n",
    "          block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "          block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "          block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "          block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.model_convolution(x)\n",
    "      x = self.layer1(x)\n",
    "      x = self.layer2(x)\n",
    "      x = self.layer3(x)\n",
    "      x = self.layer4(x)\n",
    "\n",
    "      x = self.avgpool(x)\n",
    "      x = x.reshape(x.shape[0], -1)\n",
    "      x = self.fc(x)\n",
    "\n",
    "      return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "      identity_downsample = None\n",
    "      layers = []\n",
    "\n",
    "      # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
    "      # we need to adapt the Identity (skip connection) so it will be able to be added\n",
    "      # to the layer that's ahead\n",
    "\n",
    "      if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "        identity_downsample = nn.Sequential(\n",
    "          nn.Conv2d(self.in_channels, intermediate_channels * 4, kernel_size=1, stride=stride),\n",
    "          nn.BatchNorm2d(intermediate_channels * 4),\n",
    "        )\n",
    "        layers.append(\n",
    "          block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "      # The expansion size is always 4 for ResNet 50,101,152\n",
    "      self.in_channels = intermediate_channels * 4\n",
    "\n",
    "      # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "      # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
    "      # and also same amount of channels.\n",
    "      \n",
    "      for i in range(num_residual_blocks - 1):\n",
    "        layers.append(block(self.in_channels, intermediate_channels))\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet50(img_channel=3, num_classes=1000):\n",
    "  return ResNet(CNNblock, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "def test():\n",
    "    net = ResNet50(img_channel=3, num_classes=1000)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
    "    print(y.size())\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVzgNCJjS0ug"
   },
   "source": [
    "### Model 3: Inception\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDw21sE9S0Pg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46ykaTG2Jr9l"
   },
   "source": [
    "Citations:\n",
    "\n",
    "ResNet:\n",
    "https://www.analyticsvidhya.com/blog/2021/06/build-resnet-from-scratch-with-python/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMf2X6wgXxUAWvi45/Ucwhb",
   "include_colab_link": true,
   "name": "ML_FinalProject_Submission.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
