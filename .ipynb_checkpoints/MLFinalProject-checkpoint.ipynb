{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/swadhwa5/MLFinalProject/blob/main/MLFinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7qyHA7cceuN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "from PIL import Image, ImageEnhance\n",
    "from os import listdir\n",
    "import imghdr\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage import filters\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ws1DEQyjfIyC"
   },
   "outputs": [],
   "source": [
    "# This is the beginning of the Data Augmentation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPsYqXLzcfQJ"
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "# return array of images\n",
    "def loadImages(path):\n",
    "    imagesList = listdir(path)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for image in imagesList:\n",
    "      if imghdr.what(path + image) == 'png':\n",
    "        if (image[len(image) - 13] == '1' and image[6].isalpha()): # only add 5 of each image, only add alphabetical values\n",
    "          img = Image.open(path + image)\n",
    "          imgs.append(img)\n",
    "          labels.append(image[6]) # assumes that filename structure is 'handx_[label]_....'\n",
    "    return imgs, labels\n",
    "\n",
    "# Convert png img array to array np arrays\n",
    "def ImagesToArray(imgs):\n",
    "  imgs_array = []\n",
    "  for img in imgs:\n",
    "    img_array = np.array(img)\n",
    "    imgs_array.append(img_array)\n",
    "  return imgs_array\n",
    "\n",
    "# Reshape Images   \n",
    "def shape600(x):\n",
    "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
    "  for i, img in enumerate(x):\n",
    "    x_pad_width = (600 - img.shape[0])//2\n",
    "    y_pad_width = (600 - img.shape[1])//2\n",
    "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
    "  return reshaped_array\n",
    "\n",
    "# Normalize images\n",
    "def Normalize(imgs):\n",
    "  new_imgs = []\n",
    "  for img in imgs:\n",
    "      # flat_img = img.flatten()\n",
    "      m = np.mean(img)\n",
    "      std = np.std(img)\n",
    "      img = (img-m)/std\n",
    "      new_imgs.append(img)\n",
    "  return new_imgs\n",
    "\n",
    "# x is input image, sd is how much to blur\n",
    "def blur(imgs, sd=1):\n",
    "  filtered_img = np.zeros((imgs.shape[0], 600, 600, 3))\n",
    "  for i in range(imgs.shape[0]):\n",
    "    filtered_img[i,:,:,:] = skimage.filters.gaussian(imgs[i,:,:,:], sigma=sd)\n",
    "    #filtered_img.save('./Filter_gaussian/img_' + i + '_gaussianfilt.png')\n",
    "  return filtered_img\n",
    "\n",
    "def Scale(imgs):\n",
    "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
    "  for i, img in enumerate(imgs):\n",
    "    # ratio = random.randrange(.2, .5, .1)\n",
    "    ratio = random.choice([0.1, 0.2, 0.3, 0.4])\n",
    "    x = int(ratio * 600 / 2)\n",
    "    scaled = img[x:600-x, x:600-x]\n",
    "    # scaled = cv2.imread(scaled)\n",
    "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
    "    scaled_images[i] = res\n",
    "  return scaled_images\n",
    "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
    "\n",
    "def Rotate30(imgs): \n",
    "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_dir = random.choice([-1, 1])\n",
    "    new_img = rotate(img, rand_dir * 30) \n",
    "    rot30_imgs[i, :] = new_img\n",
    "  return rot30_imgs\n",
    "\n",
    "def VerticalFlip(imgs): \n",
    "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    new_img = np.fliplr(img)\n",
    "    flip_imgs[i, :, :, :] = new_img\n",
    "  return flip_imgs\n",
    "\n",
    "def Translation(imgs): \n",
    "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_x = random.randrange(-150, 150, 50)\n",
    "    rand_y = random.randrange(-150, 150, 50)\n",
    "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
    "    new_img = warp(img,transform, mode=\"constant\")  \n",
    "    trans_imgs[i, :] = new_img\n",
    "  return trans_imgs\n",
    "\n",
    "# load png_images\n",
    "path = \"../Data_full/\"\n",
    "\n",
    "# images in an array named imgs\n",
    "imgs, labels = loadImages(path)\n",
    "\n",
    "# Step 1 convert png_images to np arrays\n",
    "imgs_array_before = ImagesToArray(imgs)\n",
    "\n",
    "def Augment(imgs_array_before, i):\n",
    "  # Step 2 Normalize images\n",
    "  imgs_array_normalize = Normalize(imgs_array_before)\n",
    "\n",
    "  # Step 3 Reshape the images\n",
    "  imgs_array_reshaped = shape600(imgs_array_normalize)\n",
    "\n",
    "  # Step 4 Blur the images\n",
    "  blurred_imgs = blur(imgs_array_reshaped, 10)\n",
    "\n",
    "  # Step 5 Scale the images\n",
    "  scaled_imgs = Scale(imgs_array_reshaped)\n",
    "\n",
    "  # Step 6 Flip the images\n",
    "  flipped_imgs = VerticalFlip(imgs_array_reshaped)\n",
    "\n",
    "  # Step 7 Add translation to images\n",
    "  translated_imgs = Translation(imgs_array_reshaped)\n",
    "\n",
    "  # Step 8 Rotate 30 Degrees\n",
    "  rotated30_imgs = Rotate30(imgs_array_reshaped)\n",
    "\n",
    "  # Step 10 combine all augmented images to np array of shape((num_augmentations + 1) * num_images, 600, 600, 3)\n",
    "  final_imgs_temp = np.concatenate((imgs_array_reshaped, blurred_imgs, scaled_imgs, translated_imgs, flipped_imgs, rotated30_imgs), 0)\n",
    "  print(final_imgs_temp.shape)\n",
    "  # np.save('../FinalImages/imgs' + str(i) + '.npy', final_imgs_temp)\n",
    "  # Show the progression of images for each step\n",
    "  # fig, ax = plt.subplots(1, 11, figsize=(15,10))\n",
    "  # ax[0].imshow(imgs_array_before[0]) # Step 1\n",
    "  # ax[1].imshow(imgs_array_normalize[0]) # Step 2\n",
    "  # ax[2].imshow(imgs_array_reshaped[0]) # Step 3\n",
    "  # ax[3].imshow(blurred_imgs[0]) # Step 4\n",
    "  # ax[4].imshow(scaled_imgs[0]) # Step 5\n",
    "  # ax[5].imshow(light_imgs[0]) # Step 6\n",
    "  # ax[6].imshow(dark_imgs[0]) # Step 6\n",
    "  # ax[7].imshow(flipped_imgs[0]) # Step 7\n",
    "  # ax[8].imshow(translated_imgs[0]) # Step 8\n",
    "  # ax[9].imshow(rotated30_imgs[0]) # Step 9\n",
    "  # ax[10].imshow(rotatedNeg30_imgs[0]) # Step 9\n",
    "  return final_imgs_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h_4V-udkZ1c"
   },
   "outputs": [],
   "source": [
    "inal_imgs = np.empty([0, 600, 600, 3])\n",
    "n = int(130/65)\n",
    "for i in range(n):\n",
    "  final_imgs_temp = Augment(imgs_array_before[i * 65:(i + 1) * 65], i)\n",
    "  final_imgs = np.concatenate((final_imgs, final_imgs_temp), 0)\n",
    "\n",
    "print(final_imgs.shape)\n",
    "np.save('../FinalImages/imgs.npy', final_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPTVahBLc2Hv"
   },
   "outputs": [],
   "source": [
    "# This is the beginning of the feature extraction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn33zskwdWAX"
   },
   "outputs": [],
   "source": [
    "# Feature: Get proportion of hand in the image\n",
    "#Load Data\n",
    "# return array of images\n",
    "def loadImages(path):\n",
    "    imagesList = listdir(path)\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for image in imagesList:\n",
    "      if imghdr.what(path + image) == 'png':\n",
    "        if (image[len(image) - 13] == '1' and image[6].isalpha()): # only add 5 of each image, only add alphabetical values\n",
    "          img = Image.open(path + image)\n",
    "          imgs.append(img)\n",
    "          labels.append(image[6]) # assumes that filename structure is 'handx_[label]_....'\n",
    "    return imgs, labels\n",
    "\n",
    "# Convert png img array to array np arrays\n",
    "def ImagesToArray(imgs):\n",
    "  imgs_array = []\n",
    "  for img in imgs:\n",
    "    img_array = np.array(img)\n",
    "    imgs_array.append(img_array)\n",
    "  return imgs_array\n",
    "\n",
    "def HandToBack(imgs):\n",
    "  features = [0] * imgs.shape[0]\n",
    "  for i in range(imgs.shape[0]):\n",
    "    img = imgs[i]\n",
    "    total_pixels = img.shape[0] * img.shape[1]\n",
    "    hand_pixels = 0\n",
    "    # mean = np.mean(img)\n",
    "    # std = np.std(img)\n",
    "    # black_pixel_val = (0 - mean) / std\n",
    "    img = np.reshape(img, (1, img.shape[0] * img.shape[1], 3))\n",
    "    for j in range (img.shape[1]):\n",
    "      if img[0][j][0] != 0 and img[0][j][1] != 0 and img[0][j][2] != 0:\n",
    "        hand_pixels += 1\n",
    "    features[i] =  hand_pixels / total_pixels\n",
    "\n",
    "  return features\n",
    "  \n",
    "# Reshape Images   \n",
    "def reshape_features(x):\n",
    "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
    "  for i, img in enumerate(x):\n",
    "    x_pad_width = (600 - img.shape[0])//2\n",
    "    y_pad_width = (600 - img.shape[1])//2\n",
    "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
    "  return reshaped_array.astype('uint8')\n",
    "\n",
    "\n",
    "def Scale_features(imgs):\n",
    "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
    "  for i, img in enumerate(imgs):\n",
    "    # ratio = random.randrange(.2, .5, .1)\n",
    "    ratio = random.choice([0.1, 0.2, 0.3, 0.4])\n",
    "    x = int(ratio * 600 / 2)\n",
    "    scaled = img[x:600-x, x:600-x]\n",
    "    # scaled = cv2.imread(scaled)\n",
    "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
    "    scaled_images[i] = res\n",
    "  return scaled_images.astype('uint8')\n",
    "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
    "\n",
    "def Rotate30_features(imgs): \n",
    "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_dir = random.choice([-1, 1])\n",
    "    new_img = rotate(img, rand_dir * 30) \n",
    "    rot30_imgs[i, :] = new_img\n",
    "  return rot30_imgs\n",
    "\n",
    "def VerticalFlip_features(imgs): \n",
    "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    new_img = np.fliplr(img)\n",
    "    flip_imgs[i, :, :, :] = new_img\n",
    "  return flip_imgs.astype('uint8')\n",
    "\n",
    "def Translation_features(imgs): \n",
    "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
    "  for i, img in enumerate(imgs): \n",
    "    rand_x = random.randrange(-150, 150, 50)\n",
    "    rand_y = random.randrange(-150, 150, 50)\n",
    "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
    "    new_img = warp(img,transform, mode=\"constant\")  \n",
    "    trans_imgs[i, :] = new_img\n",
    "  return trans_imgs\n",
    "\n",
    "def getFeaturesHandToBack(imgs_array_before, i):\n",
    "  reshaped_imgs = reshape_features(imgs_array_before)\n",
    "  scaled_imgs_new = Scale_features(reshaped_imgs)\n",
    "  translated_imgs_new = Translation_features(reshaped_imgs)\n",
    "  flipped_imgs_new = VerticalFlip_features(reshaped_imgs)\n",
    "  rotated30_imgs_new = Rotate30_features(reshaped_imgs)\n",
    "\n",
    "  fig, ax = plt.subplots(1, 5, figsize=(15,10))\n",
    "  ax[0].imshow(reshaped_imgs[0]) # Step 0\n",
    "  ax[1].imshow(scaled_imgs_new[0]) # Step 1\n",
    "  ax[2].imshow(translated_imgs_new[0]) # Step 2\n",
    "  ax[3].imshow(flipped_imgs_new[0]) # Step 3\n",
    "  ax[4].imshow(rotated30_imgs_new[0]) # Step 4\n",
    "\n",
    "  features_orig = HandToBack(reshaped_imgs) #same for orig, blurred, brightened, darkened\n",
    "  features_scaled = HandToBack(scaled_imgs_new) # for scaled\n",
    "  features_translated = HandToBack(translated_imgs_new) # for translated\n",
    "  features_flipped = HandToBack(flipped_imgs_new) # for flipped\n",
    "  features_rotated30 = HandToBack(rotated30_imgs_new) # for rotated30\n",
    "\n",
    "  features_hand_to_back_temp = np.concatenate((features_orig, features_orig, features_scaled, features_translated, features_flipped, features_rotated30), 0)\n",
    "  print(features_hand_to_back_temp.shape)\n",
    "  # np.save('../FeaturesHandToBack/features_hand_to_back' + str(i) + '.npy', features_hand_to_back_temp)\n",
    "  return features_hand_to_back_temp\n",
    "\n",
    "# load png_images\n",
    "path = \"../Data_full/\"\n",
    "# images in an array named imgs\n",
    "imgs, labels = loadImages(path)\n",
    "print(len(imgs))\n",
    "# Step 1 convert png_images to np arrays\n",
    "imgs_array_before = ImagesToArray(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9n-EHEOakk7j"
   },
   "outputs": [],
   "source": [
    "features_hand_to_back = np.empty(0)\n",
    "n = int(130/65)\n",
    "for i in range(n):\n",
    "  features_hand_to_back_temp = getFeaturesHandToBack(imgs_array_before[i * 65:(i + 1) * 65], i)\n",
    "  features_hand_to_back = np.concatenate((features_hand_to_back, features_hand_to_back_temp), 0)\n",
    "\n",
    "print(features_hand_to_back.shape)\n",
    "np.save('../FeaturesHandToBack/features_hand_to_back.npy', features_hand_to_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCAt8VbBTKpZ",
    "outputId": "728a69e7-0a97-40a1-bf55-3ca76cdef1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alphashape\n",
      "  Downloading alphashape-1.3.1-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: shapely>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from alphashape) (1.8.1.post1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from alphashape) (1.4.1)\n",
      "Collecting click-log>=0.3.2\n",
      "  Downloading click_log-0.4.0-py2.py3-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from alphashape) (1.21.6)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from alphashape) (7.1.2)\n",
      "Collecting trimesh>=3.9.8\n",
      "  Downloading trimesh-3.10.8-py3-none-any.whl (642 kB)\n",
      "\u001b[K     |████████████████████████████████| 642 kB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.7/dist-packages (from alphashape) (2.6.3)\n",
      "Collecting rtree>=0.9.7\n",
      "  Downloading Rtree-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 46.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7 in /usr/local/lib/python3.7/dist-packages (from rtree>=0.9.7->alphashape) (4.1.1)\n",
      "Installing collected packages: trimesh, rtree, click-log, alphashape\n",
      "Successfully installed alphashape-1.3.1 click-log-0.4.0 rtree-1.0.0 trimesh-3.10.8\n"
     ]
    }
   ],
   "source": [
    "!pip install alphashape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "Z4N9ehsyW8ac",
    "outputId": "a86807fc-5e1e-46e9-aaf4-cad77efd09e6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-521ae0d9d0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Feature: Get convexity of hand in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0malphashape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdescartes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolygonPatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'alphashape'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Feature: Get convexity of hand in the image\n",
    "import alphashape\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "def convex(imgs):\n",
    "  out = np.empty((imgs.shape[0], 1))\n",
    "  for i, img in enumerate(imgs): \n",
    "    orig = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "    edges = cv2.Canny(orig,250,300)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "    contours = np.concatenate(contours)\n",
    "    contours = contours.reshape((contours.shape[0], contours.shape[2]))\n",
    "\n",
    "    alpha = alphashape.alphashape(contours, .01)\n",
    "    convex = alphashape.alphashape(contours, 0.)\n",
    "\n",
    "    out[i] = (alpha.area / convex.area)\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.scatter(*zip(*contours))\n",
    "    # ax.add_patch(PolygonPatch(alpha, alpha=0.2))\n",
    "    # plt.show()\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.scatter(*zip(*contours))\n",
    "    # ax.add_patch(PolygonPatch(convex, alpha=0.2))\n",
    "    # plt.show()\n",
    "\n",
    "    # print(out[i])\n",
    "  return out\n",
    "print(convex(imgs_array_reshaped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYMsLPwRU1UW"
   },
   "outputs": [],
   "source": [
    "# Extras for Data Augmentation\n",
    "# x is input image, sd is how much to blur\n",
    "def GaussianBlur(imgs, sd=1):\n",
    "  for i, img in enumerate(imgs):\n",
    "    filtered_img = skimage.filters.gaussian(img, sigma=sd)\n",
    "    filtered_img.save('./Filter_gaussian/img_' + str(i) + '_gaussianfilt.png')\n",
    "\n",
    "import random\n",
    "def Crop(imgs):\n",
    "  n = 600\n",
    "  for i, png in enumerate(imgs): \n",
    "    ratio = random.uniform(0, 1)\n",
    "    size = n * ratio\n",
    "    x = int(size / 2)\n",
    "    img = np.asarray(png)\n",
    "    cropped = img.copy()\n",
    "    print(cropped.shape)\n",
    "    cropped[0:x] = np.zeros((n, 3))\n",
    "    cropped[img.shape[0] - x - 1:img.shape[0] - 1] = np.zeros((x, n, 3))\n",
    "    cropped[:, 0:x] = np.zeros((n, x, 3))\n",
    "    cropped[:, img.shape[1] - 1 - x:img.shape[1] - 1] = np.zeros((n, x, 3))\n",
    "    final = Image.fromarray(np.uint8(cropped*255))\n",
    "    return cropped\n",
    "    # final.save('./Crop/img_' + str(i) + '_crop.png')\n",
    "\n",
    "import cv2\n",
    "\n",
    "def Scale(imgs):\n",
    "  for i, img in enumerate(imgs):\n",
    "    ratio = random.uniform(.3, .7)\n",
    "    n = 600\n",
    "    x = int(ratio * n / 2)\n",
    "    scaled = img[x:n-x, x:n-x]\n",
    "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
    "    final = Image.fromarray(np.uint8(res*255))\n",
    "    return res\n",
    "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
    "\n",
    "### Additional Code: 4/20/22: Redid Shape function, normalize, and also completed blur. Each assumes images list --> shape-->normalize-->blur\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from tempfile import TemporaryFile\n",
    "from PIL import Image, ImageEnhance\n",
    "from os import listdir\n",
    "import imghdr\n",
    "import skimage\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage import filters\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "# uploaded = files.upload() # Get a folder named Data.zip\n",
    "\n",
    "!unzip Data2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOKpdOIwflyM",
    "outputId": "4f074cd6-7eac-4b45-f007-5b1ed7c5a7d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmdir: failed to remove './Data/.ipynb_checkpoints': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "rmdir './Data/.ipynb_checkpoints'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MLFinalProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
