{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "FeaturesHandToBack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.12 64-bit ('pytorch_p37': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "14f67cdccdf06abada5969147d66d8a0303fc958affdfcadd6d47bed05461cdf"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "import numpy as np\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "from tempfile import TemporaryFile\n",
        "from PIL import Image, ImageEnhance\n",
        "from os import listdir\n",
        "import imghdr\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "from skimage import filters\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import scipy\n",
        "import random"
      ],
      "outputs": [],
      "metadata": {
        "id": "5yCtEcTMP_1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "rmdir './Data_full/.ipynb_checkpoints'"
      ],
      "outputs": [],
      "metadata": {
        "id": "aNWyTkklQEvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "# Feature: Get proportion of hand in the image\n",
        "#Load Data\n",
        "# return array of images\n",
        "def loadImages(path):\n",
        "    imagesList = listdir(path)\n",
        "    imgs = []\n",
        "    labels = []\n",
        "    for image in imagesList:\n",
        "      if imghdr.what(path + image) == 'png':\n",
        "        img = Image.open(path + image)\n",
        "        imgs.append(img)\n",
        "        labels.append(image[6]) # assumes that filename structure is 'handx_[label]_....'\n",
        "        \n",
        "    return imgs, labels\n",
        "\n",
        "# Convert png img array to array np arrays\n",
        "def ImagesToArray(imgs):\n",
        "  imgs_array = []\n",
        "  for img in imgs:\n",
        "    img_array = np.array(img)\n",
        "    imgs_array.append(img_array)\n",
        "  return imgs_array\n",
        "\n",
        "def HandToBack(imgs):\n",
        "  features = [0] * imgs.shape[0]\n",
        "  for i in range(imgs.shape[0]):\n",
        "    img = imgs[i]\n",
        "    total_pixels = img.shape[0] * img.shape[1]\n",
        "    hand_pixels = 0\n",
        "    # mean = np.mean(img)\n",
        "    # std = np.std(img)\n",
        "    # black_pixel_val = (0 - mean) / std\n",
        "    img = np.reshape(img, (1, img.shape[0] * img.shape[1], 3))\n",
        "    for j in range (img.shape[1]):\n",
        "      if img[0][j][0] != 0 and img[0][j][1] != 0 and img[0][j][2] != 0:\n",
        "        hand_pixels += 1\n",
        "    features[i] =  hand_pixels / total_pixels\n",
        "\n",
        "  return features\n",
        "  \n",
        "# Reshape Images   \n",
        "def reshape_features(x):\n",
        "  reshaped_array = np.zeros((len(x), 600, 600, 3))\n",
        "  for i, img in enumerate(x):\n",
        "    x_pad_width = (600 - img.shape[0])//2\n",
        "    y_pad_width = (600 - img.shape[1])//2\n",
        "    reshaped_array[i,:,:,:] = np.pad(img, ((x_pad_width, x_pad_width + (img.shape[0])%2), (y_pad_width, y_pad_width+(img.shape[1]%2)), (0,0)), constant_values=img[0][0][0])\n",
        "  return reshaped_array.astype('uint8')\n",
        "\n",
        "\n",
        "def Scale_features(imgs):\n",
        "  scaled_images = np.zeros((len(imgs), 600, 600, 3))\n",
        "  for i, img in enumerate(imgs):\n",
        "    ratio = random.uniform(.3, .7)\n",
        "    x = int(ratio * 600 / 2)\n",
        "    scaled = img[x:600-x, x:600-x]\n",
        "    # scaled = cv2.imread(scaled)\n",
        "    res = cv2.resize(scaled, dsize=(600, 600), interpolation=cv2.INTER_CUBIC)\n",
        "    scaled_images[i] = res\n",
        "  return scaled_images.astype('uint8')\n",
        "    # final.save('./Crop/img_' + str(i) + '_scale.png')\n",
        "\n",
        "def Rotate30_features(imgs): \n",
        "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    new_img = rotate(img, 30) \n",
        "    rot30_imgs[i, :] = new_img\n",
        "  return rot30_imgs\n",
        "\n",
        "def RotateNeg30_features(imgs):\n",
        "  rot30_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    new_img = rotate(img, -30) \n",
        "    rot30_imgs[i, :] = new_img\n",
        "  return rot30_imgs\n",
        "\n",
        "def VerticalFlip_features(imgs): \n",
        "  flip_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    new_img = np.fliplr(img)\n",
        "    flip_imgs[i, :, :, :] = new_img\n",
        "  return flip_imgs.astype('uint8')\n",
        "\n",
        "def Translation_features(imgs): \n",
        "  trans_imgs = np.empty([imgs.shape[0], imgs.shape[1], imgs.shape[2], imgs.shape[3]])\n",
        "  for i, img in enumerate(imgs): \n",
        "    rand_x = random.randrange(-150, 150, 50)\n",
        "    rand_y = random.randrange(-150, 150, 50)\n",
        "    transform = AffineTransform(translation=(rand_x,rand_y))\n",
        "    new_img = warp(img,transform, mode=\"constant\")  \n",
        "    trans_imgs[i, :] = new_img\n",
        "  return trans_imgs\n",
        "\n",
        "def getFeaturesHandToBack(imgs_array_before, i):\n",
        "  reshaped_imgs = reshape_features(imgs_array_before)\n",
        "  scaled_imgs_new = Scale_features(reshaped_imgs)\n",
        "  translated_imgs_new = Translation_features(reshaped_imgs)\n",
        "  flipped_imgs_new = VerticalFlip_features(reshaped_imgs)\n",
        "  rotated30_imgs_new = Rotate30_features(reshaped_imgs)\n",
        "  rotatedNeg30_imgs_new = RotateNeg30_features(reshaped_imgs)\n",
        "\n",
        "  # fig, ax = plt.subplots(1, 6, figsize=(15,10))\n",
        "  # ax[0].imshow(reshaped_imgs[0]) # Step 0\n",
        "  # ax[1].imshow(scaled_imgs_new[0]) # Step 1\n",
        "  # ax[2].imshow(translated_imgs_new[0]) # Step 2\n",
        "  # ax[3].imshow(flipped_imgs_new[0]) # Step 3\n",
        "  # ax[4].imshow(rotated30_imgs_new[0]) # Step 4\n",
        "  # ax[5].imshow(rotatedNeg30_imgs_new[0]) # Step 5\n",
        "\n",
        "  features_orig = HandToBack(reshaped_imgs) #same for orig, blurred, brightened, darkened\n",
        "  features_scaled = HandToBack(scaled_imgs_new) # for scaled\n",
        "  features_translated = HandToBack(translated_imgs_new) # for translated\n",
        "  features_flipped = HandToBack(flipped_imgs_new) # for flipped\n",
        "  features_rotated30 = HandToBack(rotated30_imgs_new) # for rotated30\n",
        "  features_rotatedNeg30 = HandToBack(rotatedNeg30_imgs_new) # for rotatedNeg30\n",
        "\n",
        "  features_hand_to_back_temp = np.concatenate((features_orig, features_orig, features_orig, features_orig, features_scaled, features_translated, features_flipped, features_rotated30, features_rotatedNeg30), 0)\n",
        "  print(features_hand_to_back_temp.shape)\n",
        "  np.save('./FeaturesHandToBack/features_hand_to_back' + str(i) + '.npy', features_hand_to_back_temp)\n",
        "  return features_hand_to_back_temp\n",
        "\n",
        "# load png_images\n",
        "path = \"./Data_full/\"\n",
        "\n",
        "# images in an array named imgs\n",
        "imgs, labels = loadImages(path)\n",
        "# Step 1 convert png_images to np arrays\n",
        "imgs_array_before = ImagesToArray(imgs)\n",
        "  \n",
        "# fig, ax = plt.subplots(1, 6, figsize=(15,10))\n",
        "# ax[0].imshow(reshaped_imgs[0]) # Step 0\n",
        "# ax[1].imshow(scaled_imgs_new[0]) # Step 1\n",
        "# ax[2].imshow(translated_imgs_new[0]) # Step 2\n",
        "# ax[3].imshow(flipped_imgs_new[0]) # Step 3\n",
        "# ax[4].imshow(rotated30_imgs_new[0]) # Step 4\n",
        "# ax[5].imshow(rotatedNeg30_imgs_new[0]) # Step 5"
      ],
      "outputs": [],
      "metadata": {
        "id": "oA0r5aJpQF88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4d32919b-b375-4695-e4db-2e07fd5f7518"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "features_hand_to_back = np.empty(0)\n",
        "print(features_hand_to_back.shape)\n",
        "n = int(900/50)\n",
        "for i in range(n):\n",
        "  features_hand_to_back_temp = getFeaturesHandToBack(imgs_array_before[i * 50:(i + 1) * 50], i)\n",
        "  features_hand_to_back = np.concatenate((features_hand_to_back, features_hand_to_back_temp), 0)\n",
        "\n",
        "print(features_hand_to_back.shape)\n",
        "np.save('./FeaturesHandToBack/features_hand_to_back.npy', features_hand_to_back)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(450,)\n",
            "(8100,)\n"
          ]
        }
      ],
      "metadata": {
        "id": "dUr9DEJjQIq6"
      }
    }
  ]
}